{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195ef189",
   "metadata": {},
   "source": [
    "# MNIST Project\n",
    "> **By Jisang Yun**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feca20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff74aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Size: ' + str(len(train_dataset)) + ', Test Size: ' + str(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e55a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_data, example_labels in train_loader:\n",
    "    example_image = example_data[0]\n",
    "    print(\"Input Size:\", example_data.size())\n",
    "    \n",
    "    example_image_numpy = example_image.permute(1, 2, 0).numpy()  # Convert to HWC format for visualization\n",
    "\n",
    "    plt.imshow(example_image_numpy)\n",
    "    plt.title(f\"Label: {example_labels[0]}\")\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "\n",
    "        # Apply first convolution, batch normalization, and ReLU\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Apply second convolution and batch normalization\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Skip connection\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(SimpleCNN, self).__init__()\n",
    "    #    # Convolutional layers\n",
    "    #    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    #    self.bn1 = nn.BatchNorm2d(32)  # Batch normalization after conv1\n",
    "\n",
    "    #    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    #    self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "    #    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "    #    self.bn3 = nn.BatchNorm2d(128)\n",
    "       \n",
    "    #    # Activation and pooling layers\n",
    "    #    self.relu = nn.ReLU()\n",
    "\n",
    "       # Residual blocks\n",
    "       self.res_block1 = ResidualBlock(1, 32)\n",
    "       self.res_block2 = ResidualBlock(32, 64)\n",
    "       self.res_block3 = ResidualBlock(64, 128)\n",
    "\n",
    "       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Only define once\n",
    "       self.relu = nn.ReLU()\n",
    "       \n",
    "       # Automatically calculate the input size for fully connected layer\n",
    "       self.fc_input_size = self._get_conv_output_size()\n",
    "       \n",
    "       # Fully connected layers\n",
    "       self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "       self.dropout = nn.Dropout(0.5)\n",
    "       self.fc2 = nn.Linear(128, 20)\n",
    "       self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "   def _get_conv_output_size(self):\n",
    "       \"\"\"Automatically calculate the output size of convolutional layers\"\"\"\n",
    "       with torch.no_grad():\n",
    "           # Test with MNIST image size (1, 28, 28)\n",
    "           x = torch.zeros(1, 1, 28, 28)\n",
    "           \n",
    "           # Forward pass through conv layers\n",
    "        #    x = self.pool(self.relu(self.conv1(x)))  # 28x28 -> 14x14\n",
    "        #    x = self.pool(self.relu(self.conv2(x)))  # 14x14 -> 7x7\n",
    "        #    x = self.pool(self.relu(self.conv3(x)))  # 7x7 -> 3x3\n",
    "\n",
    "           # Forward pass through residual blocks\n",
    "           x = self.pool(self.res_block1(x))  # 28x28 -> 14x14\n",
    "           x = self.pool(self.res_block2(x))  # 14x14 -> 7x7\n",
    "           x = self.pool(self.res_block3(x))  # 7x7 -> 3x3\n",
    "           \n",
    "           return x.view(1, -1).size(1)\n",
    "\n",
    "   def forward(self, x):\n",
    "       # Convolutional layers with ReLU and pooling\n",
    "    #    x = self.pool(self.relu(self.conv1(x)))  # (batch, 32, 14, 14)\n",
    "    #    x = self.pool(self.relu(self.conv2(x)))  # (batch, 64, 7, 7)\n",
    "    #    x = self.pool(self.relu(self.conv3(x)))  # (batch, 128, 3, 3)\n",
    "       \n",
    "       # Residual blocks with pooling\n",
    "       x = self.pool(self.res_block1(x))  # (batch, 32, 14, 14)\n",
    "       x = self.pool(self.res_block2(x))  # (batch, 64, 7, 7)\n",
    "       x = self.pool(self.res_block3(x))  # (batch, 128, 3, 3)\n",
    "\n",
    "       # Flatten the tensor for fully connected layers\n",
    "       x = x.view(x.size(0), -1)  # Safer and simpler method\n",
    "       \n",
    "       # Fully connected layers\n",
    "       x = self.relu(self.fc1(x))\n",
    "       x = self.dropout(x)\n",
    "       x = self.relu(self.fc2(x))  # Add ReLU to fc2 as well\n",
    "       x = self.fc3(x)  # Final output layer (no activation)\n",
    "       \n",
    "       return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to track training loss\n",
    "train_losses = []\n",
    "epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save current batch loss\n",
    "        current_loss = loss.item()\n",
    "        train_losses.append(current_loss)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    # Calculate and store epoch average loss\n",
    "    avg_epoch_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "    epoch_losses.append(avg_epoch_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5178651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot batch-wise loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, alpha=0.7, linewidth=0.8)\n",
    "plt.title('Training Loss per Batch')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot epoch-wise average loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_losses, 'b-', linewidth=2, marker='o', markersize=3)\n",
    "plt.title('Average Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print loss statistics\n",
    "print(f\"\\nInitial Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Epoch Loss: {min(epoch_losses):.4f}\")\n",
    "print(f\"Loss Reduction: {train_losses[0] - train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().tolist())\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": range(1, len(predictions) + 1),\n",
    "    \"Label\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
