{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8904a-8730-4170-9887-9c4917395569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Project with Real-time Training Visualization / ResNet\n",
    "# By Jisang Yun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284bcac-6977-470f-bc75-6f2ff8da3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64df8e-c951-4223-9856-e421516e4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6208c-eff3-4a96-9d55-eb5a9b1efd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "print(f'Train Size: {len(train_dataset)}, Test Size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3400c4e-d550-40a9-8aa5-dd48bba9261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232ed67-7ac4-40a0-b8a0-286f3857b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Show sample image\n",
    "for example_data, example_labels in train_loader:\n",
    "    example_image = example_data[0]\n",
    "    print(\"Input Size:\", example_data.size())\n",
    "    \n",
    "    example_image_numpy = example_image.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(example_image_numpy.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Label: {example_labels[0]}\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49b20e-19df-43fa-8ebf-c5e78c09db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define ResidualBlock\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0760f-08b4-413a-aae6-d9ff96899c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define SimpleCNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.res_block1 = ResidualBlock(1, 32)\n",
    "        self.res_block2 = ResidualBlock(32, 64)\n",
    "        self.res_block3 = ResidualBlock(64, 128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_input_size = self._get_conv_output_size()\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def _get_conv_output_size(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 1, 28, 28)\n",
    "            x = self.pool(self.res_block1(x))\n",
    "            x = self.pool(self.res_block2(x))\n",
    "            x = self.pool(self.res_block3(x))\n",
    "            return x.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.res_block1(x))\n",
    "        x = self.pool(self.res_block2(x))\n",
    "        x = self.pool(self.res_block3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8a262-0982-4b54-b9ac-854eba2fea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Initialize model, loss, optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9cc8c-00e1-45e3-9422-ab99cacc8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Real-time visualization function\n",
    "def plot_training_progress(train_losses, epoch_losses, current_epoch, total_epochs):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    if train_losses:\n",
    "        ax1.plot(train_losses, alpha=0.7, linewidth=0.8, color='blue')\n",
    "        ax1.set_title(f'Training Loss per Batch (Epoch {current_epoch}/{total_epochs})')\n",
    "        ax1.set_xlabel('Batch Number')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(0, max(1.0, max(train_losses) if train_losses else 1.0))\n",
    "    \n",
    "    if epoch_losses:\n",
    "        epochs_range = range(1, len(epoch_losses) + 1)\n",
    "        ax2.plot(epochs_range, epoch_losses, 'r-', linewidth=2, marker='o', markersize=4)\n",
    "        ax2.set_title('Average Training Loss per Epoch')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Average Loss')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_xlim(0, total_epochs)\n",
    "        if epoch_losses:\n",
    "            ax2.set_ylim(0, max(epoch_losses) * 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    if train_losses:\n",
    "        print(f\"Current Batch Loss: {train_losses[-1]:.4f}\")\n",
    "    if epoch_losses:\n",
    "        print(f\"Last Epoch Average Loss: {epoch_losses[-1]:.4f}\")\n",
    "        print(f\"Best Epoch Loss: {min(epoch_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0bdd3-c701-43d7-b083-5eb77298d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Training loop\n",
    "num_epochs = 50 \n",
    "train_losses = []\n",
    "epoch_losses = []\n",
    "running_loss = 0.0\n",
    "plot_interval = 50\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        train_losses.append(current_loss)\n",
    "        epoch_loss += current_loss\n",
    "        batch_count += 1\n",
    "        running_loss += current_loss\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            avg_loss = running_loss / 100\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {avg_loss:.3f}\")\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        # Update plot every 50 batches\n",
    "        if i % plot_interval == 0:\n",
    "            plot_training_progress(train_losses, epoch_losses, epoch + 1, num_epochs)\n",
    "    \n",
    "    # End of epoch\n",
    "    avg_epoch_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "    epoch_losses.append(avg_epoch_loss)\n",
    "    plot_training_progress(train_losses, epoch_losses, epoch + 1, num_epochs)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print('Training Finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee67fd-52e0-4d67-aa5f-ebc0cdfc1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Final training visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, alpha=0.7, linewidth=0.8, color='blue')\n",
    "plt.title('Final Training Loss per Batch')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_losses, 'r-', linewidth=2, marker='o', markersize=3)\n",
    "plt.title('Final Average Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Epoch Loss: {min(epoch_losses):.4f}\")\n",
    "print(f\"Loss Reduction: {train_losses[0] - train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17897f5-3e3a-41d9-8404-5f64e4f0e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Model evaluation\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_targets)\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "predictions, true_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision_macro = precision_score(true_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(true_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Overall Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a629a-e24f-4913-9467-deb584272854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Confusion Matrix\n",
    "mnist_classes = [str(i) for i in range(10)]\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=mnist_classes,\n",
    "            yticklabels=mnist_classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed7792-4bda-4d10-b1f2-327764c6f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Per-class performance\n",
    "precision_per_class = precision_score(true_labels, predictions, average=None)\n",
    "recall_per_class = recall_score(true_labels, predictions, average=None)\n",
    "f1_per_class = f1_score(true_labels, predictions, average=None)\n",
    "\n",
    "x = np.arange(len(mnist_classes))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - width, precision_per_class, width, label='Precision', alpha=0.8)\n",
    "plt.bar(x, recall_per_class, width, label='Recall', alpha=0.8)\n",
    "plt.bar(x + width, f1_per_class, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Per-Class Performance Metrics')\n",
    "plt.xticks(x, mnist_classes)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867d1fb-4d88-4598-b06f-ee6f2d1c73c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Classification report\n",
    "print(\"Detailed Classification Report:\")\n",
    "report = classification_report(true_labels, predictions, target_names=mnist_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d348bc7-c924-4016-9dee-e084cc855b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Save submission\n",
    "print(\"Generating submission...\")\n",
    "submission_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        submission_predictions.extend(predicted.cpu().tolist())\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": range(1, len(submission_predictions) + 1),\n",
    "    \"Label\": submission_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission saved! Predictions: {len(submission_predictions)}\")\n",
    "print(f\"Final Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
