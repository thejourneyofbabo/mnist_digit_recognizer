{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5b8904a-8730-4170-9887-9c4917395569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Project with Real-time Training Visualization\n",
    "# By Jisang Yun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b284bcac-6977-470f-bc75-6f2ff8da3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d64df8e-c951-4223-9856-e421516e4fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c6208c-eff3-4a96-9d55-eb5a9b1efd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 60000, Test Size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "print(f'Train Size: {len(train_dataset)}, Test Size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3400c4e-d550-40a9-8aa5-dd48bba9261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e232ed67-7ac4-40a0-b8a0-286f3857b8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5: Show sample image\n",
    "for example_data, example_labels in train_loader:\n",
    "    example_image = example_data[0]\n",
    "    print(\"Input Size:\", example_data.size())\n",
    "    \n",
    "    example_image_numpy = example_image.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(example_image_numpy.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Label: {example_labels[0]}\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95c0760f-08b4-413a-aae6-d9ff96899c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define SimpleCNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(SimpleCNN, self).__init__()\n",
    "            \n",
    "            # Convolutional layers (moderate channel reduction: 24 → 48 → 72)\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(24)\n",
    "            self.conv2 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(48)\n",
    "            self.conv3 = nn.Conv2d(in_channels=48, out_channels=72, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn3 = nn.BatchNorm2d(72)\n",
    "            \n",
    "            # Activation and pooling layers\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.relu = nn.ReLU()\n",
    "            \n",
    "            # Hybrid approach: Partial global pooling\n",
    "            self.adaptive_pool = nn.AdaptiveAvgPool2d(2)  # (batch, 72, 2, 2) = 288 features\n",
    "            \n",
    "            # Streamlined fully connected layers\n",
    "            self.fc1 = nn.Linear(72 * 2 * 2, 128)  # 288 → 128\n",
    "            self.dropout = nn.Dropout(0.4)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Convolutional layers\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # (batch, 24, 14, 14)\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))  # (batch, 48, 7, 7)\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))  # (batch, 72, 3, 3)\n",
    "        \n",
    "        # Partial global pooling\n",
    "        x = self.adaptive_pool(x)  # (batch, 72, 2, 2)\n",
    "        \n",
    "        # Flatten and classify\n",
    "        x = x.view(x.size(0), -1)  # (batch, 288)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce8a262-0982-4b54-b9ac-854eba2fea28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EfficientSimpleCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 8: Initialize model, loss, optimizer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mSimpleCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      3\u001b[39m criterion = nn.CrossEntropyLoss()\n\u001b[32m      4\u001b[39m optimizer = optim.Adam(model.parameters(), lr=\u001b[32m0.001\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mSimpleCNN.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         \u001b[38;5;28msuper\u001b[39m(\u001b[43mEfficientSimpleCNN\u001b[49m, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n\u001b[32m      6\u001b[39m         \u001b[38;5;66;03m# Convolutional layers (moderate channel reduction: 24 → 48 → 72)\u001b[39;00m\n\u001b[32m      7\u001b[39m         \u001b[38;5;28mself\u001b[39m.conv1 = nn.Conv2d(in_channels=\u001b[32m1\u001b[39m, out_channels=\u001b[32m24\u001b[39m, kernel_size=\u001b[32m3\u001b[39m, stride=\u001b[32m1\u001b[39m, padding=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'EfficientSimpleCNN' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 8: Initialize model, loss, optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9cc8c-00e1-45e3-9422-ab99cacc8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Real-time visualization function\n",
    "def plot_training_progress(train_losses, epoch_losses, current_epoch, total_epochs):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    if train_losses:\n",
    "        ax1.plot(train_losses, alpha=0.7, linewidth=0.8, color='blue')\n",
    "        ax1.set_title(f'Training Loss per Batch (Epoch {current_epoch}/{total_epochs})')\n",
    "        ax1.set_xlabel('Batch Number')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(0, max(1.0, max(train_losses) if train_losses else 1.0))\n",
    "    \n",
    "    if epoch_losses:\n",
    "        epochs_range = range(1, len(epoch_losses) + 1)\n",
    "        ax2.plot(epochs_range, epoch_losses, 'r-', linewidth=2, marker='o', markersize=4)\n",
    "        ax2.set_title('Average Training Loss per Epoch')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Average Loss')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_xlim(0, total_epochs)\n",
    "        if epoch_losses:\n",
    "            ax2.set_ylim(0, max(epoch_losses) * 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    if train_losses:\n",
    "        print(f\"Current Batch Loss: {train_losses[-1]:.4f}\")\n",
    "    if epoch_losses:\n",
    "        print(f\"Last Epoch Average Loss: {epoch_losses[-1]:.4f}\")\n",
    "        print(f\"Best Epoch Loss: {min(epoch_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0bdd3-c701-43d7-b083-5eb77298d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Training loop\n",
    "num_epochs = 50 \n",
    "train_losses = []\n",
    "epoch_losses = []\n",
    "running_loss = 0.0\n",
    "plot_interval = 50\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        train_losses.append(current_loss)\n",
    "        epoch_loss += current_loss\n",
    "        batch_count += 1\n",
    "        running_loss += current_loss\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            avg_loss = running_loss / 100\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {avg_loss:.3f}\")\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        # Update plot every 50 batches\n",
    "        if i % plot_interval == 0:\n",
    "            plot_training_progress(train_losses, epoch_losses, epoch + 1, num_epochs)\n",
    "    \n",
    "    # End of epoch\n",
    "    avg_epoch_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "    epoch_losses.append(avg_epoch_loss)\n",
    "    plot_training_progress(train_losses, epoch_losses, epoch + 1, num_epochs)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print('Training Finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee67fd-52e0-4d67-aa5f-ebc0cdfc1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Final training visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, alpha=0.7, linewidth=0.8, color='blue')\n",
    "plt.title('Final Training Loss per Batch')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_losses, 'r-', linewidth=2, marker='o', markersize=3)\n",
    "plt.title('Final Average Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Epoch Loss: {min(epoch_losses):.4f}\")\n",
    "print(f\"Loss Reduction: {train_losses[0] - train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17897f5-3e3a-41d9-8404-5f64e4f0e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Model evaluation\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_targets)\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "predictions, true_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision_macro = precision_score(true_labels, predictions, average='macro')\n",
    "recall_macro = recall_score(true_labels, predictions, average='macro')\n",
    "f1_macro = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Overall Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a629a-e24f-4913-9467-deb584272854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Confusion Matrix\n",
    "mnist_classes = [str(i) for i in range(10)]\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=mnist_classes,\n",
    "            yticklabels=mnist_classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed7792-4bda-4d10-b1f2-327764c6f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Per-class performance\n",
    "precision_per_class = precision_score(true_labels, predictions, average=None)\n",
    "recall_per_class = recall_score(true_labels, predictions, average=None)\n",
    "f1_per_class = f1_score(true_labels, predictions, average=None)\n",
    "\n",
    "x = np.arange(len(mnist_classes))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - width, precision_per_class, width, label='Precision', alpha=0.8)\n",
    "plt.bar(x, recall_per_class, width, label='Recall', alpha=0.8)\n",
    "plt.bar(x + width, f1_per_class, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Per-Class Performance Metrics')\n",
    "plt.xticks(x, mnist_classes)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867d1fb-4d88-4598-b06f-ee6f2d1c73c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Classification report\n",
    "print(\"Detailed Classification Report:\")\n",
    "report = classification_report(true_labels, predictions, target_names=mnist_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d348bc7-c924-4016-9dee-e084cc855b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Save submission\n",
    "print(\"Generating submission...\")\n",
    "submission_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        submission_predictions.extend(predicted.cpu().tolist())\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": range(1, len(submission_predictions) + 1),\n",
    "    \"Label\": submission_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission saved! Predictions: {len(submission_predictions)}\")\n",
    "print(f\"Final Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
