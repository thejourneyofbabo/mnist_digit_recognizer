{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e4af2c",
   "metadata": {},
   "source": [
    "# MNIST with Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcac4b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjourneyofbabo\u001b[0m (\u001b[33mjourneyofbabo-hanyang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jsyun/Programming/python_ws/mnist_project/wandb/run-20250717_202134-fr38of41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn/runs/fr38of41' target=\"_blank\">mnist-cnn-test2</a></strong> to <a href='https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn' target=\"_blank\">https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn/runs/fr38of41' target=\"_blank\">https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn/runs/fr38of41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn/runs/fr38of41?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15996c980>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Import libraries and initialize W&B\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import wandb\n",
    "\n",
    "# Initialize W&B with hyperparameters\n",
    "wandb.init(project=\"mnist-cnn\", \n",
    "           name=\"mnist-cnn-test2\",\n",
    "           tags=[\"mnist-cnn\", \"test2\"],\n",
    "           config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 64,\n",
    "    \"val_split\": 0.2,\n",
    "    \"architecture\": \"SimpleCNN\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ab931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Setup device and data transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Simple data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0e545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 48000, Val: 12000, Test: 10000\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load and split dataset\n",
    "# Load MNIST dataset\n",
    "full_train_dataset = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create train/validation split\n",
    "val_split = wandb.config.val_split\n",
    "val_size = int(len(full_train_dataset) * val_split)\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "print(f'Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0794c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create data loaders\n",
    "batch_size = wandb.config.batch_size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d874409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling and activations\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 3 * 3)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f804fb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 130,890\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Initialize model, loss, and optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "# Track model with W&B\n",
    "wandb.watch(model, criterion, log=\"all\", log_freq=100)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e79406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training function with real-time metrics\n",
    "def train_epoch(model, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate batch metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_total += labels.size(0)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Log every 50 batches for real-time visualization\n",
    "        if i % 50 == 49:\n",
    "            avg_loss = running_loss / 50\n",
    "            avg_acc = 100 * running_correct / running_total\n",
    "            \n",
    "            wandb.log({\n",
    "                \"batch_train_loss\": avg_loss,\n",
    "                \"batch_train_acc\": avg_acc,\n",
    "                \"batch\": epoch * len(train_loader) + i\n",
    "            })\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            running_total = 0\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d86f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Validation function with metrics\n",
    "def validate(model, val_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # Log validation metrics\n",
    "    wandb.log({\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_accuracy\": accuracy * 100,\n",
    "        \"val_f1_score\": f1,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "    \n",
    "    return avg_val_loss, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31350174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/5 - Train Loss: 0.0681, Val Loss: 0.0717, Val Acc: 97.89%, Val F1: 0.9788\n",
      "Epoch 2/5 - Train Loss: 0.1401, Val Loss: 0.0623, Val Acc: 97.96%, Val F1: 0.9795\n",
      "Epoch 3/5 - Train Loss: 0.1916, Val Loss: 0.0413, Val Acc: 98.88%, Val F1: 0.9887\n",
      "Epoch 4/5 - Train Loss: 0.1003, Val Loss: 0.0357, Val Acc: 98.99%, Val F1: 0.9899\n",
      "Epoch 5/5 - Train Loss: 0.0213, Val Loss: 0.0354, Val Acc: 99.03%, Val F1: 0.9903\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Training loop\n",
    "print(\"Starting training...\")\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(wandb.config.epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1 = validate(model, val_loader, criterion, epoch)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{wandb.config.epochs} - '\n",
    "          f'Train Loss: {train_loss:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, '\n",
    "          f'Val Acc: {val_acc*100:.2f}%, '\n",
    "          f'Val F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        wandb.save('best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce9df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 99.15%\n",
      "Test F1 Score: 0.9914\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Test evaluation\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "test_f1 = f1_score(test_labels, test_preds, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Log test results\n",
    "wandb.log({\n",
    "    \"test_accuracy\": test_accuracy * 100,\n",
    "    \"test_f1_score\": test_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f75b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Log confusion matrix and sample predictions\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "wandb.log({\n",
    "    \"test_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "        probs=None,\n",
    "        y_true=test_labels,\n",
    "        preds=test_preds,\n",
    "        class_names=[str(i) for i in range(10)]\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53426d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Data passed to `wandb.Image` should consist of values in the range [0, 255], image data will be normalized to this range, but behavior will be removed in a future version of wandb.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Visualize sample predictions\n",
    "def log_predictions(model, test_dataset, num_samples=16):\n",
    "    model.eval()\n",
    "    indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "    images = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        image, label = test_dataset[idx]\n",
    "        image_input = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image_input)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            confidence, predicted = torch.max(probs, 1)\n",
    "            pred_label = predicted.item()\n",
    "        \n",
    "        # Create wandb Image with caption\n",
    "        caption = f\"True: {label}, Pred: {pred_label} ({confidence.item():.2f})\"\n",
    "        images.append(wandb.Image(image.squeeze().numpy(), caption=caption))\n",
    "    \n",
    "    wandb.log({\"predictions\": images})\n",
    "\n",
    "log_predictions(model, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b11330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "Best validation accuracy: 99.03%\n",
      "Final test accuracy: 99.15%\n",
      "Final test F1 score: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch_train_acc</td><td>▁▆▇▇▇███████████████████████████████████</td></tr><tr><td>batch_train_loss</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_score</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▁▇██</td></tr><tr><td>val_f1_score</td><td>▁▁▇██</td></tr><tr><td>val_loss</td><td>█▆▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>3749</td></tr><tr><td>batch_train_acc</td><td>98.8125</td></tr><tr><td>batch_train_loss</td><td>0.04963</td></tr><tr><td>best_val_accuracy</td><td>99.03333</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>final_test_accuracy</td><td>99.15</td></tr><tr><td>final_test_f1</td><td>0.99143</td></tr><tr><td>test_accuracy</td><td>99.15</td></tr><tr><td>test_f1_score</td><td>0.99143</td></tr><tr><td>total_parameters</td><td>130890</td></tr><tr><td>val_accuracy</td><td>99.03333</td></tr><tr><td>val_f1_score</td><td>0.99029</td></tr><tr><td>val_loss</td><td>0.03541</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mnist-cnn-test2</strong> at: <a href='https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn/runs/fr38of41' target=\"_blank\">https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn/runs/fr38of41</a><br> View project at: <a href='https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn' target=\"_blank\">https://wandb.ai/journeyofbabo-hanyang-university/mnist-cnn</a><br>Synced 5 W&B file(s), 17 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250717_202134-fr38of41/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 13: Final summary and cleanup\n",
    "wandb.summary.update({\n",
    "    \"best_val_accuracy\": best_val_acc * 100,\n",
    "    \"final_test_accuracy\": test_accuracy * 100,\n",
    "    \"final_test_f1\": test_f1,\n",
    "    \"total_parameters\": sum(p.numel() for p in model.parameters())\n",
    "})\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(f\"Final test accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Final test F1 score: {test_f1:.4f}\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
