{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195ef189",
   "metadata": {},
   "source": [
    "# MNIST Project\n",
    "> **By Jisang Yun**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feca20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, is_test=False):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data_frame.iloc[idx]\n",
    "\n",
    "        if self.is_test:\n",
    "            Image = item.values.reshape(28, 28).astype(np.uint8)\n",
    "            label = None\n",
    "        else:\n",
    "            Image = item[1:].values.reshape(28, 28).astype(np.uint8)\n",
    "            label = item.iloc[0]\n",
    "\n",
    "        Image = transforms.ToPILImage()(Image)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            Image = self.transform(Image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return Image\n",
    "        else:\n",
    "            return Image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d781bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomMNISTDataset(csv_file='./digit-recognizer-kaggle/train.csv', transform=transform, is_test=False)\n",
    "test_dataset = CustomMNISTDataset(csv_file='./digit-recognizer-kaggle/test.csv', transform=transform, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Size: ' + str(len(train_dataset)) + ', Test Size: ' + str(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e55a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_data, example_labels in train_loader:\n",
    "    example_image = example_data[0]\n",
    "    print(\"Input Size:\", example_data.size())\n",
    "    \n",
    "    example_image_numpy = example_image.permute(1, 2, 0).numpy()  # Convert to HWC format for visualization\n",
    "\n",
    "    plt.imshow(example_image_numpy)\n",
    "    plt.title(f\"Label: {example_labels[0]}\")\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(SimpleCNN, self).__init__()\n",
    "       # Convolutional layers\n",
    "       self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "       self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "       self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "       \n",
    "       # Activation and pooling layers\n",
    "       self.relu = nn.ReLU()\n",
    "       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Only define once\n",
    "       \n",
    "       # Automatically calculate the input size for fully connected layer\n",
    "       self.fc_input_size = self._get_conv_output_size()\n",
    "       \n",
    "       # Fully connected layers\n",
    "       self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "       self.dropout = nn.Dropout(0.5)\n",
    "       self.fc2 = nn.Linear(128, 20)\n",
    "       self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "   def _get_conv_output_size(self):\n",
    "       \"\"\"Automatically calculate the output size of convolutional layers\"\"\"\n",
    "       with torch.no_grad():\n",
    "           # Test with MNIST image size (1, 28, 28)\n",
    "           x = torch.zeros(1, 1, 28, 28)\n",
    "           \n",
    "           # Forward pass through conv layers\n",
    "           x = self.pool(self.relu(self.conv1(x)))  # 28x28 -> 14x14\n",
    "           x = self.pool(self.relu(self.conv2(x)))  # 14x14 -> 7x7\n",
    "           x = self.pool(self.relu(self.conv3(x)))  # 7x7 -> 3x3\n",
    "           \n",
    "           return x.view(1, -1).size(1)\n",
    "\n",
    "   def forward(self, x):\n",
    "       # Convolutional layers with ReLU and pooling\n",
    "       x = self.pool(self.relu(self.conv1(x)))  # (batch, 32, 14, 14)\n",
    "       x = self.pool(self.relu(self.conv2(x)))  # (batch, 64, 7, 7)\n",
    "       x = self.pool(self.relu(self.conv3(x)))  # (batch, 128, 3, 3)\n",
    "       \n",
    "       # Flatten the tensor for fully connected layers\n",
    "       x = x.view(x.size(0), -1)  # Safer and simpler method\n",
    "       \n",
    "       # Fully connected layers\n",
    "       x = self.relu(self.fc1(x))\n",
    "       x = self.dropout(x)\n",
    "       x = self.relu(self.fc2(x))  # Add ReLU to fc2 as well\n",
    "       x = self.fc3(x)  # Final output layer (no activation)\n",
    "       \n",
    "       return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().tolist())\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": range(1, len(predictions) + 1),\n",
    "    \"Label\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
